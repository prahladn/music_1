{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "Attention LSTM network .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prahladn/music_1/blob/master/Attention_LSTM_network_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ts_Eb8e-RGgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7TB9J9_4cGR",
        "colab_type": "text"
      },
      "source": [
        "# Attention LSTM Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOCUCyIA4cGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import  Input\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Layer\n",
        "import keras.backend as K\n",
        "from keras.layers import GlobalMaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence, text\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import sklearn\n",
        "from sklearn import preprocessing as skpp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep_-X0w6gmHA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1a8f6304-cb04-4274-9c4b-cf3d3249831a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqMNIFzT4cGl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "9d0401ed-1150-4deb-da52-778c4bd8c799"
      },
      "source": [
        "# Pre-processed song lyrics\n",
        "data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/original_cleaned_lyrics_100.csv')\n",
        "data.head()\n",
        "\n",
        "# English-only pre-processed song lyrics\n",
        "# data = pd.read_csv('../dataset/english_cleaned_lyrics.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>index</th>\n",
              "      <th>song</th>\n",
              "      <th>genre</th>\n",
              "      <th>lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>ego-remix</td>\n",
              "      <td>Pop</td>\n",
              "      <td>Oh baby how you doing You know I'm gonna cut r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>then-tell-me</td>\n",
              "      <td>Pop</td>\n",
              "      <td>playin everything so easy it's like you seem s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>honesty</td>\n",
              "      <td>Pop</td>\n",
              "      <td>If you search For tenderness It isn't hard to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>you-are-my-rock</td>\n",
              "      <td>Pop</td>\n",
              "      <td>Oh oh oh I oh oh oh I If I wrote a book about ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>black-culture</td>\n",
              "      <td>Pop</td>\n",
              "      <td>Party the people the people the party it's pop...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  index  ... genre                                             lyrics\n",
              "0           0      0  ...   Pop  Oh baby how you doing You know I'm gonna cut r...\n",
              "1           1      1  ...   Pop  playin everything so easy it's like you seem s...\n",
              "2           2      2  ...   Pop  If you search For tenderness It isn't hard to ...\n",
              "3           3      3  ...   Pop  Oh oh oh I oh oh oh I If I wrote a book about ...\n",
              "4           4      4  ...   Pop  Party the people the people the party it's pop...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b--FcsG54cHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numpy_data = data['lyrics'].values\n",
        "max_words = 30000\n",
        "\n",
        "# Create a new Tokenizer\n",
        "tokenizer = text.Tokenizer(num_words=max_words, oov_token='<UNK>')\n",
        "# Feed our song lyrics to the Tokenizer\n",
        "tokenizer.fit_on_texts(numpy_data)\n",
        "\n",
        "# Tokenizers come with a convenient list of words and IDs\n",
        "dictionary = tokenizer.word_index\n",
        "\n",
        "with open('dictionary.json', 'w') as dictionary_file:\n",
        "    json.dump(dictionary, dictionary_file)\n",
        "    \n",
        "tokenizer.word_index = {e:i for e,i in tokenizer.word_index.items() if i <= max_words} # because tokenizer is 1 indexed\n",
        "tokenizer.word_index[tokenizer.oov_token] = max_words + 1\n",
        "indexed_data = tokenizer.texts_to_sequences(numpy_data)\n",
        "indexed_data = np.array(indexed_data)\n",
        "\n",
        "label_encoder = skpp.LabelEncoder()\n",
        "indexed_labels = np.array(label_encoder.fit_transform(data['genre'].values))\n",
        "# label_encoder.inverse_transform(np.array([10, 8])) # To get original genre text back\n",
        "\n",
        "num_test = 30000\n",
        "\n",
        "#Shuffling\n",
        "random_indexes = np.random.permutation(len(indexed_labels))\n",
        "indexed_data = indexed_data[random_indexes]\n",
        "indexed_labels = indexed_labels[random_indexes]\n",
        "\n",
        "X_train = indexed_data[:-num_test]\n",
        "y_train = indexed_labels[:-num_test]\n",
        "X_test  = indexed_data[-num_test:]\n",
        "y_test  = indexed_labels[-num_test:]\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train)\n",
        "y_test = keras.utils.to_categorical(y_test)\n",
        "\n",
        "num_words = max_words + 2\n",
        "# Truncate and pad input sequences\n",
        "max_review_length = 1000\n",
        "\n",
        "X_train_padded = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
        "X_test_padded = sequence.pad_sequences(X_test, maxlen=max_review_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sx0tqqB-SAXY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "90b4c0a7-1484-4ddd-ca29-6c65c6e57528"
      },
      "source": [
        "\n",
        "print(X_train_padded.shape)\n",
        "print(X_test_padded.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(197449, 1000)\n",
            "(30000, 1000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JnkFu4CbfVA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class attention(Layer):\n",
        "    def __init__(self,**kwargs):\n",
        "        super(attention,self).__init__(**kwargs)\n",
        "\n",
        "    def build(self,input_shape):\n",
        "        self.W=self.add_weight(name=\"att_weight\",shape=(input_shape[-1],1),initializer=\"normal\")\n",
        "        self.b=self.add_weight(name=\"att_bias\",shape=(input_shape[1],1),initializer=\"zeros\")        \n",
        "        super(attention, self).build(input_shape)\n",
        "\n",
        "    def call(self,x):\n",
        "        et=K.squeeze(K.tanh(K.dot(x,self.W)+self.b),axis=-1)\n",
        "        at=K.softmax(et)\n",
        "        at=K.expand_dims(at,axis=-1)\n",
        "        output=x*at\n",
        "        return K.sum(output,axis=1)\n",
        "\n",
        "    def compute_output_shape(self,input_shape):\n",
        "        return (input_shape[0],input_shape[-1])\n",
        "\n",
        "    def get_config(self):\n",
        "        return super(attention,self).get_config()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPeYZWqU4cHN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "60f695dd-242b-4387-f299-f927014686d9"
      },
      "source": [
        "# Hyperparameters\n",
        "embedding_vector_length = 100\n",
        "\n",
        "#LSTM model \n",
        "model = Sequential()\n",
        "model.add(Embedding(num_words, embedding_vector_length, input_length=max_review_length))\n",
        "model.add(LSTM(60, return_sequences=True))\n",
        "model.add(attention())\n",
        "\n",
        "model.add(Dense(11, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "#early stopping\n",
        "early_stopping = EarlyStopping(monitor = 'accuracy', verbose = 1, patience = 5)\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "\n",
        "model.fit(X_train_padded, y_train, epochs=3, validation_data = (X_test_padded, y_test), batch_size=64, callbacks = [early_stopping])\n",
        "\n",
        "# Final evaluation of the model on the test set\n",
        "scores = model.evaluate(X_test_padded, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[-1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 1000, 100)         3000200   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 1000, 60)          38640     \n",
            "_________________________________________________________________\n",
            "attention_1 (attention)      (None, 60)                1060      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 11)                671       \n",
            "=================================================================\n",
            "Total params: 3,040,571\n",
            "Trainable params: 3,040,571\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/3\n",
            "3086/3086 [==============================] - 233s 75ms/step - loss: 1.4475 - accuracy: 0.5402 - val_loss: 1.3137 - val_accuracy: 0.5788\n",
            "Epoch 2/3\n",
            "3086/3086 [==============================] - 232s 75ms/step - loss: 1.2570 - accuracy: 0.5958 - val_loss: 1.2654 - val_accuracy: 0.5930\n",
            "Epoch 3/3\n",
            "3086/3086 [==============================] - 232s 75ms/step - loss: 1.1644 - accuracy: 0.6276 - val_loss: 1.2673 - val_accuracy: 0.5985\n",
            "Accuracy: 59.85%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DlLg90k4cHW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save model architecture and weights for later use\n",
        "model.save('lstm_attempt.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CcQ2FGRpvkW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}